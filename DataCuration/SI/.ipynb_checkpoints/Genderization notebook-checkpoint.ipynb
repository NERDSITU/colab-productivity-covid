{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cf5d34",
   "metadata": {},
   "source": [
    "# Gender assignment\n",
    "\n",
    "This notebook contains all processing related to the task of gender assignment described in SI. \n",
    "This project uses the commercially available service `genderize.io` to assign a binary gender label to an author's first name.   \n",
    "\n",
    "If supplied, a country code can improve the accuracy of this genderization API. Inspired by Huang et. al. (2020), we identify the most frequent country of affiliation for each author who has at least one valid affiliation country. This country is supplied to the `genderize.io` API when available. \n",
    "\n",
    "This notebook is divided into three sections:  \n",
    "1. Identifying all relevant tuples of (author first name; country) from the MAG dataset\n",
    "2. Using the genderize.io API to assign gender labels\n",
    "3. Filtering gender labelling results and merging results with the MAG author dataset.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ca051",
   "metadata": {},
   "source": [
    "# 1. Identifying the first name and country of relevant authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3ec0c",
   "metadata": {},
   "source": [
    "We use a Spark SQL to interface with the MAG dataset which is stored in text files as provided by Microsoft Academic.   \n",
    "\n",
    "\n",
    "Certain methods below use Spark SQL queries in order to interact with the MAG dataset in a manner which is largely interchangable with other SQL databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ecd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Spark-related imports, including custom library to interact with MAG on HPC\n",
    "import findspark\n",
    "import MAGspark \n",
    "\n",
    "# Set environment variables for Pyspark\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] =    # \"/home/xxxx/MAG/TMP\"\n",
    "os.environ[\"JAVA_HOME\"] =           # \"/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64\"\n",
    "os.environ['SPARK_HOME'] =          # \"/home/xxxx/MAG/spark-3.0.2-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e27bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pyspark instance on SLURM-based HPC cluster\n",
    "# NOTE: MAGspark library offers a method to run Spark on a single machine without a scheduler \n",
    "\n",
    "slurm_job_id = # 55358\n",
    "data_folderpath = # \"/home/xxxx/COLLAB/DATA/2021-08-02/\"\n",
    "\n",
    "mag, spark = MAGspark.get_mag_with_cluster_connection(jobid= slurm_job_id,                                                      \n",
    "                                                      memory_per_executor=14000,\n",
    "                                                      data_folderpath = data_folderpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f0282",
   "metadata": {},
   "source": [
    "### Compute the most frequent country of affiliation for each author\n",
    "\n",
    "First, we extract a dataset consisting of the display name and AuthorID of each author in the MAG.  \n",
    "We append to this table the most frequent country of affiliation for the authors who have at least one valid country of affiliation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ad06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_author_countries(mag, destination): \n",
    "    \"\"\"\n",
    "    Computes and writes to csv a dataset of author information from the MAG,\n",
    "    namely (AuthorId, Displayname, Country code in Iso3166 format).\n",
    "    Country code is computed as the most frequent country of affiliation\n",
    "    and can be null for authors with no affiliation country. \n",
    "    \n",
    "    Parameters: \n",
    "        @mag (MicrosoftAcademicGraph): Instance of MicrosoftAcademicGraph\n",
    "        @destination (string): filepath to store returned dataset (tab-separated)\n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize relevant MAG datasets as temporary views for Spark SQL \n",
    "    author_affiliations = mag.getDataframe('PaperAuthorAffiliations')\n",
    "    aff = mag.getDataframe('Affiliations')\n",
    "    authors = mag.getDataframe('Authors')\n",
    "    \n",
    "    # Compute the number of authorships per author and affiliation country\n",
    "    # ROW_NUMBER() is used to identify the country order for each author\n",
    "    # based on number of authorships descending\n",
    "    query = \"\"\"\n",
    "        SELECT paa.AuthorId, a.Iso3166Code as Country, COUNT(*) as num_authorships,\n",
    "        ROW_NUMBER() OVER(PARTITION BY paa.AuthorId ORDER BY COUNT(*) DESC) AS CountryRowNumber\n",
    "        FROM PaperAuthorAffiliations paa\n",
    "        INNER JOIN Affiliations AS a ON paa.AffiliationId = a.AffiliationId\n",
    "        GROUP BY paa.AuthorId, a.Iso3166Code\n",
    "    \"\"\"\n",
    "    \n",
    "    # supply query and create a temporary view, AuthorCnt\n",
    "    author_countries = mag.query_sql(query)\n",
    "    author_countries.createOrReplaceTempView('AuthorCnt')\n",
    "\n",
    "    # compute AuthorId, Displayname, Country code \n",
    "    # for each author in the MAG \n",
    "    # where country code is null of the highest-frequency country\n",
    "    query = \"\"\"\n",
    "        SELECT a.AuthorId, DisplayName, ac.Country\n",
    "        FROM Authors a \n",
    "        LEFT JOIN AuthorCnt ac ON a.AuthorId = ac.AuthorID\n",
    "        WHERE ac.CountryRowNumber is null OR ac.CountryRowNumber = 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # run query and save to file at given destination\n",
    "    author_countries_count = mag.query_sql(query)\n",
    "    author_countries_count.write.option(\"sep\", \"\\t\").option(\"encoding\", \"UTF-8\")\\\n",
    "    .csv(destination)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = # e.g. \"../DATA/2021-08-02/project/AuthorCountries.txt\"\n",
    "extract_author_countries(mag, destination=destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec013fd",
   "metadata": {},
   "source": [
    "### Compute all relevant tuples of (firstname, country)  \n",
    "\n",
    "Next we compute all unique pairs of first name and country.   \n",
    "The first name of an author is defined as everything preceding the first space in an author's name.   \n",
    "\n",
    "Here, we also filter out all authors who are not relevant to the study; those who only published prior to 2010 or in non-STEM disciplines.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53dc355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_firstnames_per_country(mag): \n",
    "    \"\"\"\n",
    "    Computes the unique tuples of (first name, country code) \n",
    "    for authors who published at least once in STEM-disciplines \n",
    "    in 2010 or later. Country code can be null.\n",
    "    Parameters: \n",
    "        @mag (MicrosoftAcademicGraph): Instance of MicrosoftAcademicGraph\n",
    "    Returns\n",
    "        Pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize relevant MAG datasets as temporary views for Spark SQL \n",
    "    ac = mag.getDataframe('AuthorCountries')\n",
    "    author_affiliations = mag.getDataframe('PaperAuthorAffiliations')\n",
    "    papers = mag.getDataframe('Papers')\n",
    "    prf = mag.getDataframe('PaperRootField')\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT\n",
    "        LEFT(DisplayName, POSITION(' ' in DisplayName) - 1) as Firstname,\n",
    "        a.Country\n",
    "        FROM AuthorCountries a\n",
    "        INNER JOIN (\n",
    "            SELECT DISTINCT(AuthorId) as AuthorId\n",
    "            FROM PaperAuthorAffiliations paau\n",
    "            INNER JOIN PaperRootField prfi ON paau.PaperId = prfi.PaperId\n",
    "            INNER JOIN Papers p ON paau.PaperId = p.PaperID\n",
    "            WHERE IsStem = 1 AND p.Year >= 2010\n",
    "        ) ua ON a.AuthorId = ua.AuthorId\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run query and output to Pandas dataframe\n",
    "    stem_authors = mag.query_sql(query)\n",
    "    stem_authors_df = stem_authors.toPandas()\n",
    "    \n",
    "    return stem_authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4655c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_authors_df = unique_surnames_per_country(mag)\n",
    "\n",
    "\n",
    "# Store the result as comma-separated csv with Pandas\n",
    "destination = # e.g. '.../DATA/2021-08-02/project/AuthorFirstnames.csv'\n",
    "stem_authors_df.to_csv(destination, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d250ae",
   "metadata": {},
   "source": [
    "## 2. Genderize names\n",
    "\n",
    "We now have all the name and country pairs to supply to the `genderize.io` API.   \n",
    "We use a temporary SQLite database to store the progress of the genderization process, \n",
    "as each request to the API can only supply gender labels for a maxiumum of 10 names. As such, this process is time consuming and prone to interruptions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a path for a temporary SQLite database file\n",
    "DB_PATH = # e.g. \".../DATA/2021-08-02/project/ATTRIBUTES.db\"\n",
    "\n",
    "# set the CSV filepath of the file containing name + country pairs\n",
    "CSV_PATH = # e.g. '.../DATA/2021-08-02/project/AuthorFirstnames.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef754a",
   "metadata": {},
   "source": [
    "We define a few helper function to interact with the SQLite database \n",
    "using Pandas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839afc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    initialize connection instance to SQLite database \n",
    "    located at given path\n",
    "    Parameters:\n",
    "        @dp_path (string): Path to SQLite .db file\n",
    "    Returns:\n",
    "        Sqlite3 connection instance\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path, timeout=30)\n",
    "    return conn\n",
    "\n",
    "def append_to_db(conn, table, df):\n",
    "    \"\"\"\n",
    "    Append contents of a dataframe to a database table\n",
    "    Parameters:\n",
    "        @df (DataFrame): Records to append \n",
    "        @table (string): Table name\n",
    "        @conn (Connection): SQLite3 .db connection\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.to_sql(table, con=conn, if_exists='append')\n",
    "\n",
    "def query_sql(conn, query):\n",
    "    \"\"\"\n",
    "    Query SQLite database with SQL query\n",
    "    Parameters: \n",
    "        @conn (Connection): SQLite3 .db connection\n",
    "        @query (string): SQL query\n",
    "    Returns:\n",
    "        Query result as Pandas dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, con=conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5178a",
   "metadata": {},
   "source": [
    "Next, we define a function to supply a list of max. 10 names to the `genderize.io` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe786273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key to genderize.io API: \n",
    "API_KEY = \"\"\n",
    "\n",
    "\n",
    "def genderize_names(namelist, country=None):\n",
    "    \"\"\"\n",
    "    Supplies a list of max. 10 names and an optional country code\n",
    "    to the genderize.io API and returns a list of results from the API.\n",
    "    Parameters: \n",
    "        @namelist (list): List of first names (string) to genderize \n",
    "        @country (string): Optional country code\n",
    "    Returns: \n",
    "        List of API results for given names\n",
    "    \"\"\"\n",
    "    \n",
    "    # break if list of names is longer than 10\n",
    "    assert len(namelist) <= 10\n",
    "\n",
    "    url = \"https://api.genderize.io/?\"\n",
    "    api_key = API_KEY\n",
    "\n",
    "    # join all names into URL-format required by genderize.io\n",
    "    # example: \"name=peter&name=alicia&country_id=US\"\n",
    "    names_string = \"&\".join(['name=' + str(name) for name in namelist])\n",
    "    request_url  = url + names_string \n",
    "\n",
    "    # add country if given\n",
    "    request_url  = request_url + '&country_id=' + country if country is not None else request_url\n",
    "\n",
    "    # send request to API\n",
    "    r = requests.get(request_url + '&apikey=' + api_key)\n",
    "\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    # extract JSON response\n",
    "    result = r.json()\n",
    "\n",
    "    # return list of results\n",
    "    if not isinstance(result, list):\n",
    "        return [result]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdfffb",
   "metadata": {},
   "source": [
    "Finally, we define a function to run the genderization process for all relevant first name + country pairs, including those with no country.  \n",
    "\n",
    "In case the process is interrupted it can be rerun and will not supply name + country pairs already genderized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_names():\n",
    "    \"\"\"\n",
    "    Runs all name + country pairs through the genderize.io API \n",
    "    and stores results in SQLite database in table 'genderize'\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read list of first name and country codes from CSV file\n",
    "    name_list = pd.read_csv(CSV_PATH)\n",
    "    \n",
    "    # Sort list by country code\n",
    "    name_list.sort_values(by=['Country', 'Surname'], inplace=True)\n",
    "    \n",
    "    # get a database connection to SQLite database\n",
    "    conn = get_conn()\n",
    "\n",
    "    # Extract already genderized name + country pairs \n",
    "    finished_names = query_sql(conn, \"SELECT name as Firstname, country_id as Country FROM genderize\")\n",
    "\n",
    "    # Remove name + country pairs already genderized\n",
    "    name_list = pd.concat([name_list, finished_names]).drop_duplicates(keep=False)\n",
    "\n",
    "    # Loop over each country + None as country code\n",
    "    for country in sorted([cnt for cnt in name_list['Country'].unique()] + [None]):\n",
    "        \n",
    "        # Filter the name list for current country:\n",
    "        if country is None:\n",
    "            name_list_country = name_list[pd.isnull(name_list['Country'])]\n",
    "        else:\n",
    "            name_list_country = name_list[name_list['Country'] == country]\n",
    "\n",
    "        print(\"STARTING NAMES FROM {}\".format(country))\n",
    "        \n",
    "        # loop over all names in batches of 10\n",
    "        for i in tqdm(range(0, name_list_country.shape[0], 10)):\n",
    "            \n",
    "            # get list of names\n",
    "            current_names = [name for name, country \n",
    "                             in list(name_list_country.iloc[i:i+10].values)]\n",
    "            \n",
    "            # supply names to API\n",
    "            result = genderize_names(current_names, country=country)\n",
    "\n",
    "            # convert JSON result to Pandas dataframe\n",
    "            result_df = pd.DataFrame.from_records(result)\n",
    "            \n",
    "            # Skip if API returned errorful response\n",
    "            if 'error' in result_df.columns:\n",
    "                print(\"failed on {}\".format(current_names))\n",
    "                continue\n",
    "            \n",
    "            # add country_id None to results if no country was specified\n",
    "            if 'country_id' not in result_df.columns:\n",
    "                result_df['country_id'] = None\n",
    "            \n",
    "            # append results to 'generize' table in SQLite database\n",
    "            result_df.to_sql('genderize', con=conn, if_exists='append')\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157df161",
   "metadata": {},
   "source": [
    "## 3. Filtering gender labelling results and merging results with the MAG author dataset\n",
    "\n",
    "We add a number of filters to the genderization results to eliminate potentially errorful gender labels.   \n",
    "Names with a single character and punctuation should not be genderized (e.g. \"J. Smith\"), for example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9206bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get connection to SQLite database and extract all genderization results\n",
    "conn = get_conn()\n",
    "all_results = query_sql(conn, \"SELECT * FROM genderize\")\n",
    "\n",
    "# remove duplicates for good measure\n",
    "all_results.drop_duplicates(subset=['name', 'country_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac1fa2",
   "metadata": {},
   "source": [
    "Next we load the CSV of first names and country codes and merge genderization results to this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnames = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# merge genderization results and author names df:\n",
    "merged = pd.merge(firstnames, all_results, how='left', \n",
    "                  left_on=['Firstname', 'Country'], \n",
    "                  right_on=['name', 'country_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bf7a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Firstname</th>\n",
       "      <th>Country</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>probability</th>\n",
       "      <th>count</th>\n",
       "      <th>country_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Omar</td>\n",
       "      <td>male</td>\n",
       "      <td>0.98</td>\n",
       "      <td>68333.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Francois</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Francois</td>\n",
       "      <td>male</td>\n",
       "      <td>0.98</td>\n",
       "      <td>26836.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Igor</td>\n",
       "      <td>US</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Igor</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>312.0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bastiaan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bastiaan</td>\n",
       "      <td>male</td>\n",
       "      <td>0.99</td>\n",
       "      <td>561.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Serlyana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Serlyana</td>\n",
       "      <td>female</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651077</th>\n",
       "      <td>Sahir-Halouane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sahir-Halouane</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651078</th>\n",
       "      <td>Chul-Sup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chul-Sup</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651079</th>\n",
       "      <td>Anuron</td>\n",
       "      <td>IN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Anuron</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651080</th>\n",
       "      <td>Tahzibi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Tahzibi</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651081</th>\n",
       "      <td>Iseh</td>\n",
       "      <td>NG</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Iseh</td>\n",
       "      <td>female</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3651082 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Firstname Country  index            name  gender  probability  \\\n",
       "0                  Omar     NaN    9.0            Omar    male         0.98   \n",
       "1              Francois     NaN    1.0        Francois    male         0.98   \n",
       "2                  Igor      US    7.0            Igor    male         1.00   \n",
       "3              Bastiaan     NaN    8.0        Bastiaan    male         0.99   \n",
       "4              Serlyana     NaN    9.0        Serlyana  female         1.00   \n",
       "...                 ...     ...    ...             ...     ...          ...   \n",
       "3651077  Sahir-Halouane     NaN    5.0  Sahir-Halouane    None         0.00   \n",
       "3651078        Chul-Sup     NaN    3.0        Chul-Sup    None         0.00   \n",
       "3651079          Anuron      IN    7.0          Anuron    None         0.00   \n",
       "3651080         Tahzibi     NaN    8.0         Tahzibi    None         0.00   \n",
       "3651081            Iseh      NG    8.0            Iseh  female         1.00   \n",
       "\n",
       "           count country_id  \n",
       "0        68333.0       None  \n",
       "1        26836.0       None  \n",
       "2          312.0         US  \n",
       "3          561.0       None  \n",
       "4            1.0       None  \n",
       "...          ...        ...  \n",
       "3651077      0.0       None  \n",
       "3651078      0.0       None  \n",
       "3651079      0.0         IN  \n",
       "3651080      0.0       None  \n",
       "3651081      3.0         NG  \n",
       "\n",
       "[3651082 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28781f0",
   "metadata": {},
   "source": [
    "Next we define a set of rules to filter the genderization results:  \n",
    "1. Names for which `genderize.io` returned None are labelled -2 \n",
    "2. Names of length 1 when stripping punctuation \".\" are labelled -2, e.g. \"J. Smith\"\n",
    "3. Names of length 4 in full and length 2 when stripping punctuation \".\" are labelled -2, e.g. \"H.J. Smith\"  \n",
    "4. Names of length 2 containing only consonants are labelled -2, e.g. \"HJ Smith\"\n",
    "5. Names with a 'male' confidence score of >= 0.8 are labelled 0 (Male)\n",
    "6. Names with a 'female' confidence score of >= 0.8 are labelled 1 (Female)\n",
    "7. All other names are labelled -1. These will mostly names with a gender label of lower confidence than 0.8.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3befc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rem_vowel(string):\n",
    "    # removes vowels from a string\n",
    "    return (re.sub(\"[aeiouæøåAEIOUÆØÅ]\", \"\", string)) \n",
    "\n",
    "\n",
    "def assign_gender_label(rowrecord): \n",
    "    \"\"\"\n",
    "    Takes a record (dict) from the dataset of author names \n",
    "    and genderization results and returns gender labels \n",
    "    according to a set of rules. \n",
    "    Returns: \n",
    "        Gender label (int): 0 for male, 1 for female, -1 or -2 for unlabelled\n",
    "    \"\"\"\n",
    "    if pd.isnull(rowrecord.gender): return -2\n",
    "    elif len(rowrecord.Firstname.replace(\".\", \"\")) == 1: return -2 \n",
    "    elif len(rowrecord.Firstname) == 4 and len(rowrecord.Firstname.replace(\".\", \"\")) == 2: return -2\n",
    "    elif len(rowrecord.Firstname) == 2 and len(rem_vowel(rowrecord.Firstname)) == 2: return -2 \n",
    "    elif rowrecord.gender == 'male' and rowrecord.probability >= 0.8: return 0\n",
    "    elif rowrecord.gender == 'female' and rowrecord.probability >= 0.8: return 1\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0e36a",
   "metadata": {},
   "source": [
    "We now apply the filter to the existing dataframe of author names and gender assignment results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a06ba3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['genderized'] = merged.apply(lambda rowrecord: assign_gender_label(rowrecord), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b24746",
   "metadata": {},
   "source": [
    "The result is stored as a tab-separated CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9868512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = # e.g. '.../DATA/2021-08-02/project/GenderizedFirstnames.txt'\n",
    "\n",
    "merged[['Firstname', 'Country', 'gender', \n",
    "        'probability', 'count', 'genderized']]\\\n",
    "        .to_csv(destination,sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f588ba",
   "metadata": {},
   "source": [
    "### Merge genderized names to authors in the MAG\n",
    "Finally, we can merge the genderization results onto individual author records in the MAG.  \n",
    "The dataset of genderization results has been added to the MAG dataset under the table name `GenderizedFirstnames`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_genders_to_authors(mag, destination): \n",
    "    \"\"\"\n",
    "    Merge genderization results with MAG author records\n",
    "    to obtain a gender label for each available author in the MAG. \n",
    "    Parameters: \n",
    "        @mag (MicrosoftAcademicGraph): Instance of MicrosoftAcademicGraph\n",
    "        @destination (string): filepath to store returned dataset (tab-separated)\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # load relevant datasets from MAG as temp. views\n",
    "    ac = mag.getDataframe('AuthorCountries')\n",
    "    genderized = mag.getDataframe('GenderizedFirstnames')\n",
    "    \n",
    "    # Query selects from AuthorCountries and (left) joins genderizaton results\n",
    "    # on first name and country\n",
    "    query = \"\"\"\n",
    "        SELECT \n",
    "            ac.AuthorId,\n",
    "            ac.DisplayName, \n",
    "            ac.Country,\n",
    "            gs.gender,\n",
    "            COALESCE(gs.genderized, -3) as genderized\n",
    "        FROM AuthorCountries ac \n",
    "        LEFT JOIN GenderizedFirstnames gs ON \n",
    "            LEFT(ac.DisplayName, POSITION(' ' in ac.DisplayName) - 1) = gs.Firstname AND\n",
    "            COALESCE(ac.Country, 'unknown') = COALESCE(gs.Country, 'unknown')\n",
    "        ORDER BY gs.genderized DESC, ac.AuthorId\n",
    "    \"\"\"\n",
    "    \n",
    "    author_genders = mag.query_sql(query)\n",
    "    \n",
    "    # write to file\n",
    "    author_genders.write.option(\"sep\", \"\\t\").option(\"encoding\", \"UTF-8\")\\\n",
    "    .csv(destination)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65421efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = # e.g. \".../DATA/2021-08-02/project/AuthorsGenderized.txt\"\n",
    "assign_genders_to_authors(mag, destination=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5e063",
   "metadata": {},
   "source": [
    "The AuthorsGenderized dataset now consists of records with the following columns:  \n",
    "* AuthorId\n",
    "* Displayname\n",
    "* Country (by majority affiliation)\n",
    "* Gender (string from genderize.io) \n",
    "* Genderized (1 for female, 0 for male, < 0 for unlabelled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
